{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "from rapidfuzz import fuzz\n",
    "from rapidfuzz.distance import Levenshtein\n",
    "import unicodedata\n",
    "\n",
    "from ann_levenshtein import LevenshteinIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/IMK품목마스터.txt', delimiter='\\t', dtype=str)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['description'] = data[['영문품명', '한글품명', '규격', '모델명', '제조원명']].astype(str).agg(\" \".join, axis=1)\n",
    "data['label'] = data['품목코드']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['label', 'description']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    def remove_dup(t):\n",
    "        sp_str = t.split()\n",
    "        return \" \".join(sorted(set(sp_str), key=sp_str.index))\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    # text = text.lower()  # 소문자로 변환\n",
    "\n",
    "    # 패턴 제거: (주), (유)\n",
    "    text = re.sub(r'\\(주\\)|\\(유\\)', '', text)\n",
    "\n",
    "    # 특수문자 제거 (온점, 쉼표, 물결표 제외)\n",
    "    special_chars = r'[()\\[\\]/#φΦØø￠★@%※□:;\"＇，_\\-!&+=≥±`\\'\\\"←→↑↓↔↕\\\\\\^]'\n",
    "    text = re.sub(special_chars, ' ', text)\n",
    "\n",
    "    # 숫자 사이에 있는 .(소숫점 표시) ,(천의 자리 표시), ~(범위 표시)는 유지, 나머지 .,~ 삭제\n",
    "    text = re.sub(r'(?<!\\d)[.,~]|[.,~](?!\\d)', ' ', text)\n",
    "\n",
    "    # 숫자 사이의 ~만 유지\n",
    "    text = re.sub(r'\\s*~\\s*', '~', text)  # ~ 앞뒤의 공백 삭제 (ex. 10~100, 10 ~ 100 둘 다 가능하게)\n",
    "    text = re.sub(r'(?<!\\d)~|~(?!\\d)', ' ', text)  # ~ 앞뒤가 숫자가 아니면 삭제\n",
    "\n",
    "\n",
    "    # 불필요 문구 제거 (공통 패턴)\n",
    "    common_patterns = [\n",
    "        '세부구성 이미지\\s?참고','첨부\\s?이미지\\s?참고','이미지\\s?참조','요청사항\\s?참조','명판\\s?참조','물류이용불가 품목',\n",
    "        '일반화물택배발송','주문수입품목으로 교환\\s?반품\\s?불가','주문제작품으로 교환\\s?반품\\s?불가','교환 및 반품\\s?불가',\n",
    "        '규격\\s?참조','첨부\\s?참조','규격\\s?참고','도면\\s?참조','사양서\\s?참조','주문시\\s?사이즈\\s?기재','추가발주불가',\n",
    "        '재고\\s?문의\\s?주세요','주문전\\s?재고\\s?확인\\s?바랍니다','첨부파일 참조','참조s?제작s?할s?것','교환\\s?반품\\s?불가',\n",
    "        '도면rev \\d+참조','도묜참조','구매\\s?시방서참조','구매시방참조','사진s?참고','사양서s?참고','사영서s?참고',\n",
    "        '도면\\s?참고','사양\\s?참고','상세정보 첨부참고','상세정보\\s?참고','첨부 참고'\n",
    "    ]\n",
    "    text = re.sub(r'|'.join(common_patterns), \"\", text)\n",
    "    \n",
    "    # 재고 관련 문구 제거\n",
    "    inventory_patterns = [\n",
    "        r\"재고 없을\\s?시 \\d+일\\s?소요\", r\"재고 미보유시 \\d+일\\s?소요\", r'재고\\s?소진\\s?시 납기 \\d+일',\n",
    "        r'재고 소진\\s?시 공급\\s?불가', r'재고 소진\\s?시 납품\\s?불가', r'재고 소진\\s?시 공급\\s?불가\\s?상품',\n",
    "        r'재고 소진\\s?시 \\d+일 소요', r'국내 재고 소진\\s?시 납기 약\\s?\\d+개월 소요',\n",
    "        r'재고 소진\\s?시 표준납기\\s?\\d+일 소요', r'재고 소진\\s?시 최소주문수량 적용상품',\n",
    "        r'재고 없을\\s?때 \\d+일\\s?소요', r'재고 없을\\s?시 표준납기 \\d+일\\s?소요',\n",
    "        r'재고 없을\\s?시 제작\\s?납기 \\d+일\\s?소요', r'수입품목으로 재고 없을\\s?시 납기 \\d+\\s?\\d+일\\s?소요',\n",
    "        r'재고 미보유\\s?시 \\d+일 이상 소요', r'재고 미보유\\s?시 납기\\s?\\d+일',\n",
    "        r'재고\\s?소진\\s?시 발주\\s?취소 가능성', r'재고 보유\\s?시 \\d+일 소요',\n",
    "        r'재고s?소진 후 구매s?불가', r'재고 보유\\s?시 \\d+일\\s?이내',\n",
    "        r'재고 미보유\\s?시 표준납기 \\d+일\\s?소요'\n",
    "    ]\n",
    "    text = re.sub(r'|'.join(inventory_patterns), \"\", text)\n",
    "    \n",
    "    # 추가적 문구 제거\n",
    "    remove_terms = ['인쇄없음', '시중품', '주식회사', '유한회사']\n",
    "    text = re.sub(r'|'.join(remove_terms), \"\", text)\n",
    "\n",
    "    # 텍스트 치환\n",
    "    text = text.replace('nan', ' ')\n",
    "    text = text.replace('| ', ' ').replace(' |', ' ').replace('||', ' ')\n",
    "    text = re.sub(r'[xX×*＊]', 'x', text)  # 곱하기 기호 통일\n",
    "    text = text.replace('ℓ', 'l')  # 리터 기호 통일\n",
    "\n",
    "    # 한자 제거\n",
    "    text = re.sub(r'[\\u4E00-\\u9FFF]', '', text)\n",
    "\n",
    "    # 중복된 단어 제거\n",
    "    text = remove_dup(text)\n",
    "    \n",
    "    # 여러 공백을 하나의 공백으로 변환\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['description'] = data['description'].map(preprocessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('Data/IMK_master.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = data['description'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(string) for string in strings]\n",
    "print(lengths[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(lengths, bins=75, edgecolor='black')\n",
    "# plt.title(\"Distribution of String Lengths in IMK master\")\n",
    "# plt.xlabel(\"String Length\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tree_num=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/IMK_master.txt', delimiter='\\t', dtype=str)\n",
    "# data = pd.read_csv('Data/Random_strings_0.1K.txt', header=None)\n",
    "data['label'] = data['label'].astype(str)\n",
    "data['description'] = data['description'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000800</td>\n",
       "      <td>Fly Swatter 파리채 L520mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000002100</td>\n",
       "      <td>Insecticide 살충제 500ml 수성에어졸 무향 파리 모기등의살충제 안전기준...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                        description\n",
       "0  1000000800                             Fly Swatter 파리채 L520mm\n",
       "1  1000002100  Insecticide 살충제 500ml 수성에어졸 무향 파리 모기등의살충제 안전기준..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2538466\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 3.98 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create and configure index\n",
    "leven_index = LevenshteinIndex(\n",
    "    num_trees=2,\n",
    "    num_strings=len(data),\n",
    "    split_num=200,\n",
    "    weights=(1, 1, 1)\n",
    ")\n",
    "\n",
    "# for num_trees=2, len(data)~2.5M, split_num=200\n",
    "# CPU times: total: 0 ns\n",
    "# Wall time: 3.99 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.33 s\n",
      "Wall time: 4.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Add strings in bulk\n",
    "leven_index.add_items_bulk(data['description'])\n",
    "\n",
    "# for num_trees=2, len(data)~2.5M, split_num=200\n",
    "# CPU times: total: 4.14 s\n",
    "# Wall time: 4.18 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "Python int too large to convert to C long",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOverflowError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed eval>:2\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Documents\\Projects\\ANN_Levenshtein\\ann_levenshtein\\Levenshtein_ANN.py:169\u001b[39m, in \u001b[36mLevenshteinIndex.build\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_trees):\n\u001b[32m    168\u001b[39m     tree, tree_map = \u001b[38;5;28mself\u001b[39m._build_tree(\u001b[38;5;28mself\u001b[39m._string_buffer, np.arange(\u001b[38;5;28mself\u001b[39m.num_strings))\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m     tree = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m     tree = tree[np.argsort(tree[:, \u001b[32m0\u001b[39m])]  \u001b[38;5;66;03m# sort by node_idx\u001b[39;00m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28mself\u001b[39m.trees.append(tree)\n",
      "\u001b[31mOverflowError\u001b[39m: Python int too large to convert to C long"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Build index\n",
    "leven_index.build()\n",
    "\n",
    "# for num_trees=2, len(data)~2.5M, split_num=200\n",
    "# CPU times: total: 2min 32s\n",
    "# Wall time: 2min 34s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 203 ms\n",
      "Wall time: 194 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# save\n",
    "leven_index.save(\"Models/LevenshteinIndex_IMK_master_2tree\")\n",
    "\n",
    "# for num_trees=2, len(data)~2.5M, split_num=200\n",
    "# CPU times: total: 1min 58s\n",
    "# Wall time: 2min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: F Killer 에프킬라 500ml 킨 에스씨존슨코리아\n",
      "Top 5 nearest neighbors:\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Query\n",
    "query = data['description'][5]\n",
    "neighbors = leven_index.get_nns_by_string(query, topk=5)\n",
    "\n",
    "print(\"Query:\", query)\n",
    "print(\"Top 5 nearest neighbors:\")\n",
    "if neighbors is not None:\n",
    "    for idx in neighbors:\n",
    "        print(f\"{idx}, {leven_index.get_strings()[idx]}\")\n",
    "\n",
    "# for num_trees=2, len(data)~2.5M, split_num=200\n",
    "# 2.5M 데이터에서 top5 유사품목 1번 검색하는데 걸리는 시간\n",
    "# CPU times: total: 141 ms\n",
    "# Wall time: 135 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.66 s\n",
      "Wall time: 4.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "leven_index = LevenshteinIndex(num_trees=1, num_strings=len(data), split_num=200)\n",
    "leven_index.add_items_bulk(data['description'])\n",
    "leven_index.load(\"Models/LevenshteinIndex_IMK_master_2tree\")\n",
    "\n",
    "# for num_trees=2, len(data)~2.5M, split_num=200\n",
    "# CPU times: total: 41.1 s\n",
    "# Wall time: 41.2 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: F Killer 에프킬라 500ml 킨 에스씨존슨코리아\n",
      "Top 5 nearest neighbors:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:7\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Query\n",
    "query = data['description'][5]\n",
    "neighbors = leven_index.get_nns_by_string(query, topk=5)\n",
    "\n",
    "print(\"Query:\", query)\n",
    "print(\"Top 5 nearest neighbors:\")\n",
    "if neighbors is not None:\n",
    "    for idx in neighbors:\n",
    "        print(f\"{idx}, {leven_index.get_strings()[idx]}\")\n",
    "\n",
    "# 2.5M 데이터에서 top5 유사품목 1번 검색하는데 걸리는 시간\n",
    "# CPU times: total: 141 ms\n",
    "# Wall time: 142 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tree_num=10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/IMK_master.txt', delimiter='\\t', dtype=str)\n",
    "# data = pd.read_csv('Data/Random_strings_0.1K.txt', header=None)\n",
    "data['label'] = data['label'].astype(str)\n",
    "data['description'] = data['description'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000800</td>\n",
       "      <td>Fly Swatter 파리채 L520mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000002100</td>\n",
       "      <td>Insecticide 살충제 500ml 수성에어졸 무향 파리 모기등의살충제 안전기준...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                        description\n",
       "0  1000000800                             Fly Swatter 파리채 L520mm\n",
       "1  1000002100  Insecticide 살충제 500ml 수성에어졸 무향 파리 모기등의살충제 안전기준..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2538466\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 109 ms\n",
      "Wall time: 114 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create and configure index\n",
    "leven_index = LevenshteinIndex(\n",
    "    num_trees=10,\n",
    "    num_strings=len(data),\n",
    "    split_num=200,\n",
    "    weights=(1, 1, 1)\n",
    ")\n",
    "\n",
    "\n",
    "# for num_trees=10, len(data)~2.5M, split_num=200\n",
    "# CPU times: total: 0 ns\n",
    "# Wall time: 2.99 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.25 s\n",
      "Wall time: 4.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Add strings in bulk\n",
    "leven_index.add_items_bulk(data['description'])\n",
    "\n",
    "# for num_trees=10, len(data)~2.5M, split_num=200\n",
    "# CPU times: total: 4.39 s\n",
    "# Wall time: 4.42 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed eval>:2\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Documents\\Projects\\ANN_Levenshtein\\ann_levenshtein\\Levenshtein_ANN.py:167\u001b[39m, in \u001b[36mLevenshteinIndex.build\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_trees):\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m         tree, tree_map = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_string_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_strings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m         tree = np.array(tree, dtype=np.int32)\n\u001b[32m    169\u001b[39m         tree = tree[np.argsort(tree[:, \u001b[32m0\u001b[39m])]  \u001b[38;5;66;03m# sort by node_idx\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Documents\\Projects\\ANN_Levenshtein\\ann_levenshtein\\Levenshtein_ANN.py:94\u001b[39m, in \u001b[36mLevenshteinIndex._build_tree\u001b[39m\u001b[34m(self, strings, indices, tree, tree_map, depth, node_idx)\u001b[39m\n\u001b[32m     91\u001b[39m right_indices = indices[~mask]\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# node.left\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m*\u001b[49m\u001b[43mnode_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# node.right\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[38;5;28mself\u001b[39m._build_tree(strings, right_indices, tree, tree_map, depth + \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m*node_idx+\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Documents\\Projects\\ANN_Levenshtein\\ann_levenshtein\\Levenshtein_ANN.py:94\u001b[39m, in \u001b[36mLevenshteinIndex._build_tree\u001b[39m\u001b[34m(self, strings, indices, tree, tree_map, depth, node_idx)\u001b[39m\n\u001b[32m     91\u001b[39m right_indices = indices[~mask]\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# node.left\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m*\u001b[49m\u001b[43mnode_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# node.right\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[38;5;28mself\u001b[39m._build_tree(strings, right_indices, tree, tree_map, depth + \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m*node_idx+\u001b[32m1\u001b[39m)\n",
      "    \u001b[31m[... skipping similar frames: LevenshteinIndex._build_tree at line 94 (18 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Documents\\Projects\\ANN_Levenshtein\\ann_levenshtein\\Levenshtein_ANN.py:94\u001b[39m, in \u001b[36mLevenshteinIndex._build_tree\u001b[39m\u001b[34m(self, strings, indices, tree, tree_map, depth, node_idx)\u001b[39m\n\u001b[32m     91\u001b[39m right_indices = indices[~mask]\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# node.left\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m*\u001b[49m\u001b[43mnode_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# node.right\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[38;5;28mself\u001b[39m._build_tree(strings, right_indices, tree, tree_map, depth + \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m*node_idx+\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Documents\\Projects\\ANN_Levenshtein\\ann_levenshtein\\Levenshtein_ANN.py:96\u001b[39m, in \u001b[36mLevenshteinIndex._build_tree\u001b[39m\u001b[34m(self, strings, indices, tree, tree_map, depth, node_idx)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28mself\u001b[39m._build_tree(strings, left_indices, tree, tree_map, depth + \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m*node_idx)\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# node.right\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m*\u001b[49m\u001b[43mnode_idx\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# moved to self.build() for not sorting at every level of recursion.\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# tree = np.array(tree, dtype=np.int32)\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# tree = tree[np.argsort(tree[:, 0])]  # sort by node_idx\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tree, tree_map\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Documents\\Projects\\ANN_Levenshtein\\ann_levenshtein\\Levenshtein_ANN.py:68\u001b[39m, in \u001b[36mLevenshteinIndex._build_tree\u001b[39m\u001b[34m(self, strings, indices, tree, tree_map, depth, node_idx)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# node = [node_idx, s1_idx, s2_idx]\u001b[39;00m\n\u001b[32m     67\u001b[39m node = [node_idx, indices[\u001b[32m0\u001b[39m], indices[\u001b[32m1\u001b[39m]]\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m(node)\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# tree_map = {node_idx: (s1_idx, s2_idx)}\u001b[39;00m\n\u001b[32m     70\u001b[39m tree_map[node_idx] = (indices[\u001b[32m0\u001b[39m], indices[\u001b[32m1\u001b[39m])\n",
      "\u001b[31mAttributeError\u001b[39m: 'int' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Build index\n",
    "leven_index.build()\n",
    "\n",
    "# for num_trees=10, len(data)~2.5M, split_num=200\n",
    "# CPU times: total: 23min 57s\n",
    "# Wall time: 24min 2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 234 ms\n",
      "Wall time: 221 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# save\n",
    "leven_index.save(\"Models/LevenshteinIndex_IMK_master_10tree\")\n",
    "\n",
    "# for num_trees=10, len(data)~2.5M, split_num=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: F Killer 에프킬라 500ml 킨 에스씨존슨코리아\n",
      "Top 5 nearest neighbors:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:7\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Query\n",
    "query = data['description'][5]\n",
    "neighbors = leven_index.get_nns_by_string(query, topk=5)\n",
    "\n",
    "print(\"Query:\", query)\n",
    "print(\"Top 5 nearest neighbors:\")\n",
    "if neighbors is not None:\n",
    "    for idx in neighbors:\n",
    "        print(f\"{idx}, {leven_index.get_strings()[idx]}\")\n",
    "\n",
    "# for num_trees=10, len(data)~2.5M, split_num=200``\n",
    "# 2.5M 데이터에서 top5 유사품목 1번 검색하는데 걸리는 시간\n",
    "# CPU times: total: 3 s\n",
    "# Wall time: 5.89 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tree_num = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 3.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create index \n",
    "leven_index = LevenshteinIndex(\n",
    "    num_trees=100,\n",
    "    num_strings=len(data),\n",
    "    split_num=200,\n",
    "    weights=(1, 1, 1)\n",
    ")\n",
    "\n",
    "\n",
    "# for num_trees=100, len(data)~2.5M, split_num=200\n",
    "# CPU times: total: 4.48 s\n",
    "# Wall time: 5.29 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m# add data\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mleven_index.add_items_bulk(data[\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdescription\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m])\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m# for num_trees=100, len(data)~2.5M, split_num=200\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m# CPU times: total: 3.7 s\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m# Wall time: 4.43 s\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Documents\\Projects\\ANN_Levenshtein\\venv_ANN_Leven\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2542\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2540\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2541\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2542\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2544\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2545\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2546\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2547\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Documents\\Projects\\ANN_Levenshtein\\venv_ANN_Leven\\Lib\\site-packages\\IPython\\core\\magics\\execution.py:1372\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1370\u001b[39m         \u001b[38;5;28mself\u001b[39m.shell.showtraceback()\n\u001b[32m   1371\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1372\u001b[39m     end = \u001b[43mclock2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1374\u001b[39m     st = clock2()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Documents\\Projects\\ANN_Levenshtein\\venv_ANN_Leven\\Lib\\site-packages\\IPython\\utils\\timing.py:70\u001b[39m, in \u001b[36mclock2\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;66;03m# There is no distinction of user/system time under windows, so we just use\u001b[39;00m\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# time.process_time() for everything...\u001b[39;00m\n\u001b[32m     68\u001b[39m     clocku = clocks = clock = time.process_time\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclock2\u001b[39m():\n\u001b[32m     71\u001b[39m \u001b[38;5;250m        \u001b[39m\u001b[33;03m\"\"\"Under windows, system CPU time can't be measured.\u001b[39;00m\n\u001b[32m     72\u001b[39m \n\u001b[32m     73\u001b[39m \u001b[33;03m        This just returns process_time() and zero.\"\"\"\u001b[39;00m\n\u001b[32m     74\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m time.process_time(), \u001b[32m0.0\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# add data\n",
    "leven_index.add_items_bulk(data['description'])\n",
    "\n",
    "# for num_trees=100, len(data)~2.5M, split_num=200\n",
    "# CPU times: total: 3.7 s\n",
    "# Wall time: 4.43 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed eval>:2\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Documents\\Projects\\ANN_Levenshtein\\ann_levenshtein\\Levenshtein_ANN.py:132\u001b[39m, in \u001b[36mLevenshteinIndex.build\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_trees):\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m         tree = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_string_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_strings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m         \u001b[38;5;28mself\u001b[39m.trees.append(tree)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Documents\\Projects\\ANN_Levenshtein\\ann_levenshtein\\Levenshtein_ANN.py:78\u001b[39m, in \u001b[36mLevenshteinIndex._build_tree\u001b[39m\u001b[34m(self, strings, indices, depth)\u001b[39m\n\u001b[32m     75\u001b[39m right_indices = indices[mask]\n\u001b[32m     77\u001b[39m node.left = \u001b[38;5;28mself\u001b[39m._build_tree(strings, left_indices, depth + \u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m node.right = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Documents\\Projects\\ANN_Levenshtein\\ann_levenshtein\\Levenshtein_ANN.py:78\u001b[39m, in \u001b[36mLevenshteinIndex._build_tree\u001b[39m\u001b[34m(self, strings, indices, depth)\u001b[39m\n\u001b[32m     75\u001b[39m right_indices = indices[mask]\n\u001b[32m     77\u001b[39m node.left = \u001b[38;5;28mself\u001b[39m._build_tree(strings, left_indices, depth + \u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m node.right = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "    \u001b[31m[... skipping similar frames: LevenshteinIndex._build_tree at line 78 (2 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Documents\\Projects\\ANN_Levenshtein\\ann_levenshtein\\Levenshtein_ANN.py:77\u001b[39m, in \u001b[36mLevenshteinIndex._build_tree\u001b[39m\u001b[34m(self, strings, indices, depth)\u001b[39m\n\u001b[32m     74\u001b[39m left_indices = indices[~mask]\n\u001b[32m     75\u001b[39m right_indices = indices[mask]\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m node.left = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m node.right = \u001b[38;5;28mself\u001b[39m._build_tree(strings, right_indices, depth + \u001b[32m1\u001b[39m)\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Documents\\Projects\\ANN_Levenshtein\\ann_levenshtein\\Levenshtein_ANN.py:77\u001b[39m, in \u001b[36mLevenshteinIndex._build_tree\u001b[39m\u001b[34m(self, strings, indices, depth)\u001b[39m\n\u001b[32m     74\u001b[39m left_indices = indices[~mask]\n\u001b[32m     75\u001b[39m right_indices = indices[mask]\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m node.left = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m node.right = \u001b[38;5;28mself\u001b[39m._build_tree(strings, right_indices, depth + \u001b[32m1\u001b[39m)\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "    \u001b[31m[... skipping similar frames: LevenshteinIndex._build_tree at line 78 (18 times), LevenshteinIndex._build_tree at line 77 (16 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Documents\\Projects\\ANN_Levenshtein\\ann_levenshtein\\Levenshtein_ANN.py:78\u001b[39m, in \u001b[36mLevenshteinIndex._build_tree\u001b[39m\u001b[34m(self, strings, indices, depth)\u001b[39m\n\u001b[32m     75\u001b[39m right_indices = indices[mask]\n\u001b[32m     77\u001b[39m node.left = \u001b[38;5;28mself\u001b[39m._build_tree(strings, left_indices, depth + \u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m node.right = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Documents\\Projects\\ANN_Levenshtein\\ann_levenshtein\\Levenshtein_ANN.py:77\u001b[39m, in \u001b[36mLevenshteinIndex._build_tree\u001b[39m\u001b[34m(self, strings, indices, depth)\u001b[39m\n\u001b[32m     74\u001b[39m left_indices = indices[~mask]\n\u001b[32m     75\u001b[39m right_indices = indices[mask]\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m node.left = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m node.right = \u001b[38;5;28mself\u001b[39m._build_tree(strings, right_indices, depth + \u001b[32m1\u001b[39m)\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Documents\\Projects\\ANN_Levenshtein\\ann_levenshtein\\Levenshtein_ANN.py:59\u001b[39m, in \u001b[36mLevenshteinIndex._build_tree\u001b[39m\u001b[34m(self, strings, indices, depth)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28mself\u001b[39m.tf_array[indices[\u001b[32m1\u001b[39m], depth] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m LevenshteinNode(indices[\u001b[32m0\u001b[39m], indices[\u001b[32m1\u001b[39m], depth)\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m s1_idx, s2_idx = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m node = LevenshteinNode(s1_idx, s2_idx, depth)\n\u001b[32m     62\u001b[39m mask = []\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# build index\n",
    "leven_index.build()\n",
    "\n",
    "# for num_trees=100, len(data)~2.5M, split_num=200\n",
    "# CPU times: total: 4h 15s\n",
    "# Wall time: 4h 11min 56s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed eval>:2\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Documents\\Projects\\ANN_Levenshtein\\ann_levenshtein\\Levenshtein_ANN.py:193\u001b[39m, in \u001b[36mLevenshteinIndex.save\u001b[39m\u001b[34m(self, filename)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    192\u001b[39m     main_result = \u001b[38;5;28mself\u001b[39m.trees, \u001b[38;5;28mself\u001b[39m.tf_array\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m     \u001b[43mpickle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mMemoryError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# save\n",
    "leven_index.save(\"Models/LevenshteinIndex_IMK_master_100tree\")\n",
    "\n",
    "# for num_trees=100, len(data)~2.5M, split_num=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: F Killer 에프킬라 500ml 킨 에스씨존슨코리아\n",
      "Top 5 nearest neighbors:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:8\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Query\n",
    "query = data['description'][5]\n",
    "\n",
    "neighbors = leven_index.get_nns_by_string(query, topk=5)\n",
    "\n",
    "print(\"Query:\", query)\n",
    "print(\"Top 5 nearest neighbors:\")\n",
    "if neighbors is not None:\n",
    "    for idx in neighbors:\n",
    "        print(f\"{idx}, {leven_index.get_strings()[idx]}\")\n",
    "\n",
    "# for num_trees=100, len(data)~2.5M, split_num=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leven_index=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search ALL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz.distance import Levenshtein\n",
    "import unicodedata\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "# Hangul Decomposition function using unicodedata\n",
    "def decompose_hangul(text, *args, **kwargs):\n",
    "    decomposed = ''\n",
    "    for char in text:\n",
    "        if '가' <= char <= '힣':\n",
    "            # Hangul syllables range: decompose\n",
    "            decomposed += unicodedata.normalize('NFD', char)\n",
    "        else:\n",
    "            decomposed += char\n",
    "    return decomposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: F Killer 에프킬라 500ml 킨 에스씨존슨코리아\n",
      "Top 5 nearest neighbors:\n",
      "5, F Killer 에프킬라 500ml 킨 에스씨존슨코리아\n",
      "761, F Killer 에프킬라 500ml 무향 에스씨존슨코리아\n",
      "478288, F Killer 에프킬라 500ml 안전기준 확인 에스씨존슨코리아\n",
      "1686149, F Killer 에프킬라 500ml 내추럴 후레쉬 오렌지향 에스씨존슨코리아\n",
      "298290, F Killer 에프킬라 500ml 무향 다이버시코리아\n",
      "CPU times: total: 1.88 s\n",
      "Wall time: 3.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query = data['description'][5]\n",
    "\n",
    "# Add a new column with fuzz.ratio distances to the query string\n",
    "# data['sim'] = data['description'].map(lambda x: fuzz.ratio(query, x, processor=decompose_hangul))\n",
    "data['sim'] = data['description'].map(lambda x: fuzz.ratio(query, x))\n",
    "\n",
    "\n",
    "# Sort and take top 5\n",
    "top5 = data.sort_values('sim', ascending=False).head(5)  # Higher ratio = more similar\n",
    "\n",
    "# Display\n",
    "print(\"Query:\", query)\n",
    "print(\"Top 5 nearest neighbors:\")\n",
    "for _, row in top5.iterrows():\n",
    "    print(f\"{row.name}, {row['description']}\")\n",
    "# 2.5M 데이터에서 top5 유사품목 1번 검색하는데 걸리는 시간\n",
    "# CPU times: total: 1.88 s\n",
    "# Wall time: 3.04 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: F Killer 에프킬라 500ml 킨 에스씨존슨코리아\n",
      "Top 5 nearest neighbors:\n",
      "5, F Killer 에프킬라 500ml 킨 에스씨존슨코리아\n",
      "761, F Killer 에프킬라 500ml 무향 에스씨존슨코리아\n",
      "478288, F Killer 에프킬라 500ml 안전기준 확인 에스씨존슨코리아\n",
      "298290, F Killer 에프킬라 500ml 무향 다이버시코리아\n",
      "1023965, F Killer 에프킬라 500ml스프레이형 무향\n",
      "CPU times: total: 1.62 s\n",
      "Wall time: 1.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query = data['description'][5]\n",
    "\n",
    "# Add a new column with fuzz.ratio distances to the query string\n",
    "data['sim'] = data['description'].astype(str).map(lambda x: Levenshtein.distance(query, x))\n",
    "\n",
    "\n",
    "# Sort and take top 5\n",
    "top5 = data.sort_values('sim', ascending=True).head(5)  # Small score = more similar\n",
    "\n",
    "# Display\n",
    "print(\"Query:\", query)\n",
    "print(\"Top 5 nearest neighbors:\")\n",
    "for _, row in top5.iterrows():\n",
    "    print(f\"{row.name}, {row['description']}\")\n",
    "\n",
    "# 2.5M 데이터에서 top5 유사품목 1번 검색하는데 걸리는 시간\n",
    "# CPU times: total: 1.62 s\n",
    "# Wall time: 1.63 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ANN_Leven",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
